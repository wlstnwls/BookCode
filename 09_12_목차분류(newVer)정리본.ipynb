{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce9db2a6",
   "metadata": {},
   "source": [
    "# library & data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2f58a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6942e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loading file\n",
    "df = pd.read_excel('') # 파일경로\n",
    "df['txtb_id'] = df['isbn'].apply(lambda x : f'm{x}') # txtb_id \n",
    "df['set_isbn'] = df['set_isbn'].replace(np.NaN,0).astype(str).apply(lambda x: x[:-2]) # 널값 대체 및 타입변경\n",
    "\n",
    "# 타깃 분리 및 단권, 세트권 분리\n",
    "total = df.loc[df['id'].isin(target)] # target 존재시\n",
    "onePart = total.loc[total['set_isbn'] == '0', :] # 단권\n",
    "setPart = total.loc[total['set_isbn']!='0',:] # 세트권\n",
    "\n",
    "# 인덱스 초기화\n",
    "onePart.index = range(len(onePart)) \n",
    "setPart.index = range(len(setPart))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc03429",
   "metadata": {},
   "source": [
    "# function defining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84eec28",
   "metadata": {},
   "outputs": [],
   "source": [
    "## A\n",
    "def index_classification(isbn, tit, text, i, ex):\n",
    "    code = isbn[i] # isbn, main_title\n",
    "#     title = tit[i]\n",
    "#     d1,d2,d3,d4 = 0,0,0,0  # 뎁스 채울 변수(초기화)\n",
    "    if '목차 더보기' in text: # 잘못 들어간 단어 삭제(틀 전체로 접근하다 보니 같이 달려옴)\n",
    "        text.remove('목차 더보기')\n",
    "    text = [clear_text(r) for r in text] # 2\n",
    "    text = [delete_text(r) for r in text] # 3\n",
    "    splitKwd,index_ls, splitKwd_ls, page_ls,etc_ls = classification_contents(text,ex)\n",
    "    if '총론' in splitKwd and '각론' in splitKwd:\n",
    "        splitKwd.remove('각론')\n",
    "        splitKwd_ls = ['총론' if c == '각론' else c for c in splitKwd_ls]\n",
    "    \n",
    "    if 'check' not in splitKwd:\n",
    "        tcntnID = [f'n{f\"{i}\".zfill(3)}' for i in range(len(splitKwd_ls))] # 바로저장으로 수정+ 전달도 있어야 함\n",
    "        dep = assign_depth(splitKwd_ls)\n",
    "        bin_ls = circle(splitKwd_ls,splitKwd)\n",
    "        high = assign_highID(tcntnID, dep)#assign_floor_index(myID, dep) # assign_high(ck_ls, myID, pandan) # high_depthID(ck_ls, pandan,myID)\n",
    "        study = assign_study(dep) \n",
    "        \n",
    "        no_ls = notStudy_change(index_ls)\n",
    "        no_lss = zero_ls(bin_ls, no_ls)\n",
    "        check_study(study, dep, etc_ls)\n",
    "        print(no_lss)\n",
    "        try:\n",
    "            zero_change(high, dep, study, no_lss)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        for ti in tcntnID:\n",
    "            mokchaID.append(ti)\n",
    "        for ii in index_ls:\n",
    "            contents.append(ii)\n",
    "        for pi in page_ls:\n",
    "            start_pn.append(pi)\n",
    "        for di in dep:\n",
    "            depth.append(di)\n",
    "        for hi in high:\n",
    "            high_mokchaID.append(hi)\n",
    "        for si in study:\n",
    "            learning.append(si)   \n",
    "        for ei in etc_ls:\n",
    "            etc.append(ei)\n",
    "        for j in range(len(index_ls)):\n",
    "            bookID.append(code)\n",
    "    else:\n",
    "        noList.append(code)  # 수정함\n",
    "#         etc.append('check')\n",
    "#         for j in [mokchaID, high_mokchaID, contents, learning, depth, start_pn, etc]:\n",
    "#             j.append(np.Na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5727a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 정제 함수\n",
    "# 1\n",
    "def make_ls(c,i): # 인덱스 리스트와 순서를 받음\n",
    "    matches = c[i].split('-+-')\n",
    "    return matches\n",
    "# # 1번의 이전 버전\n",
    "# def make_ls(c,i): # 인덱스 리스트와 순서를 받음\n",
    "#     matches = re.findall(r\"'(.*?)'\", c[i])\n",
    "#     return list(matches)\n",
    "\n",
    "# 2\n",
    "def clear_text(sentence):  # 목차 내용 정제 함수\n",
    "    pattern = r'[\\w가-힣]+'\n",
    "    extracted = re.findall(pattern, sentence)\n",
    "    result = ' '.join(extracted)\n",
    "    return result\n",
    "\n",
    "# 3\n",
    "def delete_text(sentence):\n",
    "    pattern = r'u3000|u000|u00|uf0ab|u2005|'#목차 더보기'\n",
    "    result = re.sub(pattern, '', sentence)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d36bbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 판별 함수\n",
    "# 1\n",
    "def classification_contents(text, ex): # 판별 요소 설정 함수\n",
    "    pd_l,ck_l, ck_ls,pn_l, etc_l = [],[],[],[],[]\n",
    "    for idx, line in enumerate(text):\n",
    "        a = re.sub(r'(?![ⅠⅡⅢⅣⅤⅥⅦⅧⅨⅩ])\\S', '', line).strip()\n",
    "        # 숫자 판별\n",
    "        l, page, k= split_page(line)\n",
    "        if line[0].isnumeric() == True: \n",
    "            if a != '' and 'roma' not in pd_l: # 로마 숫자\n",
    "                ck_l.append(l) # 위치 저장\n",
    "                pn_l.append(page)\n",
    "                ck_ls.append('roma')\n",
    "                pd_l.append('roma')\n",
    "                o = classification_roma(line)\n",
    "                etc_l.append([o,k])\n",
    "            elif a != '' and 'roma' in pd_l: # 로마 숫자\n",
    "                ck_l.append(l) # 위치 저장\n",
    "                pn_l.append(page)\n",
    "                ck_ls.append('roma')\n",
    "                o = classification_roma(line)\n",
    "                etc_l.append([o,k])\n",
    "            elif a == '' and line[1] in ['부', '절','편','강'] and 'num' not in pd_l :\n",
    "                ck_l.append(l)\n",
    "                pn_l.append(page)\n",
    "                ck_ls.append('num')\n",
    "                pd_l.append('num') # 분류랑 숫자 결합\n",
    "                o = classification_num(line)\n",
    "                etc_l.append([o,k])\n",
    "            elif a == '' and line[1] in ['부', '절','편','강'] and 'num' in pd_l:\n",
    "                ck_l.append(l)\n",
    "                pn_l.append(page)\n",
    "                ck_ls.append('num')\n",
    "                o = classification_num(line)\n",
    "                etc_l.append([o,k])\n",
    "            elif a == '' and line[1] not in ['부', '절','편','강'] and 'ara' not in pd_l :\n",
    "                ck_l.append(l)\n",
    "                pn_l.append(page)\n",
    "                ck_ls.append('ara')\n",
    "                pd_l.append('ara') # 분류랑 숫자 결합\n",
    "                o = classification_ara(line)\n",
    "                etc_l.append([o,k])\n",
    "            elif a == '' and line[1] not in ['부', '절','편','강'] and 'ara' in pd_l:\n",
    "                ck_l.append(l)\n",
    "                pn_l.append(page)\n",
    "                ck_ls.append('ara')\n",
    "                o = classification_ara(line)\n",
    "                etc_l.append([o,k])\n",
    "        elif line[0].isnumeric() != True:   # 포함되는 리스트\n",
    "            t = re.sub(r'[^a-zA-Z가-힣]','',line.lower())  # 기록 시에는 line을 기록해야 함\n",
    "            b = ex.match(t)\n",
    "            if b and b.group() not in pd_l:\n",
    "                pd_l.append(b.group())\n",
    "                ck_l.append(l)\n",
    "                pn_l.append(page)\n",
    "                ck_ls.append(b.group())\n",
    "                o = classification_ex(line, b)\n",
    "                etc_l.append([o,k])\n",
    "            elif b and b.group() in pd_l:\n",
    "                ck_l.append(l)\n",
    "                pn_l.append(page)\n",
    "                ck_ls.append(b.group())\n",
    "                o = classification_ex(line, b)\n",
    "                etc_l.append([o,k])\n",
    "                pass\n",
    "            else:\n",
    "                pd_l.append('check')\n",
    "                \n",
    "    return pd_l, ck_l,ck_ls, pn_l,etc_l\n",
    "\n",
    "# 2\n",
    "def classification_roma(line):\n",
    "    o =''\n",
    "    test = line.split(' ')\n",
    "    test = [1 for t in test if re.sub(r'(?![ⅠⅡⅢⅣⅤⅥⅦⅧⅨⅩ])\\S','', t) != '']\n",
    "    if sum(test)> 1:\n",
    "        o = 'over'\n",
    "    else:\n",
    "        o = 0\n",
    "    return o\n",
    "\n",
    "# 3\n",
    "def classification_ara(line):\n",
    "    o =''\n",
    "    test = line.split(' ')\n",
    "    test = [1 for t in test if t.isnumeric() == True]\n",
    "    if sum(test)> 1:\n",
    "        o = 'over'\n",
    "    else:\n",
    "        o = 0\n",
    "    return o    \n",
    "\n",
    "# 4\n",
    "def classification_num(line):\n",
    "    o =''\n",
    "    if line.count(line[1]) > 1:\n",
    "        o = 'over'\n",
    "    else:\n",
    "        o = 0\n",
    "    return o    \n",
    "\n",
    "# 5\n",
    "def classification_ex(line, b):\n",
    "    o =''\n",
    "    if line.count(b.group())>1:\n",
    "        o = 'over'\n",
    "    else:\n",
    "        o = 0  \n",
    "    return o\n",
    "\n",
    "# 6\n",
    "def split_page(line): # 페이지 분리 함수 |Ⅸ\n",
    "    texts = line.split(' ')\n",
    "    if len(texts) >= 2:\n",
    "        l = texts[-1]\n",
    "        ll = texts[-2]\n",
    "        a = re.sub(r'(?![ⅠⅡⅢⅣⅤⅥⅦⅧⅨⅩ])\\S', '', l).strip()\n",
    "        b = re.sub(r'(?![ⅠⅡⅢⅣⅤⅥⅦⅧⅨⅩ])\\S', '', ll).strip()\n",
    "        if l.isnumeric() == True and a == '':\n",
    "            if ll.isnumeric() == True and b == '':\n",
    "                page = l\n",
    "                line = ' '.join(line.split(' ')[:-1])\n",
    "                if len(page) > 3:\n",
    "                    k = 'pn'\n",
    "                else:\n",
    "                    k = 'pn'\n",
    "            elif ll.isnumeric() == True and b != '':\n",
    "                page = l\n",
    "                line = ' '.join(line.split(' ')[:-1])\n",
    "                if len(page) > 3:\n",
    "                    k = 'pn'\n",
    "                else:\n",
    "                    k = 0\n",
    "            else:\n",
    "                page = l\n",
    "                line = ' '.join(line.split(' ')[:-1])\n",
    "                if len(page) > 3:\n",
    "                    k = 'pn'\n",
    "                else:\n",
    "                    k = 0\n",
    "        else:\n",
    "            page = np.NaN\n",
    "            k = 0\n",
    "    else:\n",
    "        l = texts[-1]\n",
    "        a = re.sub(r'(?![ⅠⅡⅢⅣⅤⅥⅦⅧⅨⅩ])\\S', '', l).strip()\n",
    "        if l.isnumeric() == True and a == '':\n",
    "            page = l\n",
    "            line = ' '.join(line.split(' ')[:-1])\n",
    "            if len(page) > 3:\n",
    "                k = 'pn'\n",
    "            else:\n",
    "                k = 0\n",
    "        else:\n",
    "            page = np.NaN\n",
    "            k = 0\n",
    "    return line, page, k \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e37a566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 작업 함수\n",
    "\n",
    "# 1\n",
    "def circle(ck_ls,splitKwd):  # 구역 판별\n",
    "    bin_ls = []\n",
    "    x = -1\n",
    "    for i in ck_ls:\n",
    "        if i == splitKwd[0]:\n",
    "            x += 1\n",
    "            bin_ls.append(x)\n",
    "        else:\n",
    "            bin_ls.append(x)\n",
    "    return bin_l\n",
    "\n",
    "# 2\n",
    "def assign_study(depth):\n",
    "    study = []\n",
    "    for i in range(len(depth)):\n",
    "        if i == 0:\n",
    "            if depth[i] == depth[i+1]:\n",
    "                study.append('Y')\n",
    "            else:\n",
    "                study.append('N')\n",
    "        elif i != len(depth)-1:\n",
    "            if depth[i] == depth[i+1] or depth[i] == depth[i-1]:\n",
    "                study.append('Y')\n",
    "            else:\n",
    "                study.append('N')\n",
    "        else:\n",
    "            study.append(study[-1])\n",
    "    return study\n",
    "\n",
    "# 3\n",
    "def assign_depth(lst):  # 뎁스 판별\n",
    "    dep_ls = []\n",
    "    dep = 1\n",
    "    depth_map = {}\n",
    "    for element in lst:\n",
    "        if element not in depth_map:\n",
    "            depth_map[element] = dep\n",
    "            dep += 1\n",
    "        dep_ls.append(depth_map[element])\n",
    "    return dep_ls\n",
    "\n",
    "# 4\n",
    "def assign_highID(myID, dep): # 상위 뎁스 판단 함수\n",
    "    high = []\n",
    "    depth_dic = {}\n",
    "    for i in range(len(dep)):\n",
    "        if dep[i] == 1:\n",
    "            high.append('')\n",
    "            depth_dic[dep[i]] = myID[i]\n",
    "        elif dep[i] == 2:\n",
    "            high.append(depth_dic[1])\n",
    "            depth_dic[dep[i]] = myID[i]\n",
    "        elif dep[i] == 3:\n",
    "            high.append(depth_dic[2])\n",
    "            depth_dic[dep[i]] = myID[i]\n",
    "        elif dep[i] == 4:\n",
    "            high.append(depth_dic[3])\n",
    "            depth_dic[dep[i]] = myID[i]\n",
    "        elif dep[i] == 5:\n",
    "            high.append(depth_dic[4])\n",
    "            depth_dic[dep[i]] = myID[i]\n",
    "        else:\n",
    "            high.append('?')\n",
    "    return high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712b4cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 후속 함수      \n",
    "# 1 \n",
    "def notStudy_change(contents): # 학습연계가 N인 요소 판별(분류된것중 해당 단어 체크)\n",
    "    ls = []\n",
    "    a = re.compile('부록')\n",
    "    b = re.compile('정답|해설|색인')\n",
    "    for i,v in enumerate(contents):\n",
    "        if a.match(v):\n",
    "            ls.append(i)\n",
    "        elif b.search(v):\n",
    "            ls.append(i)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    return ls\n",
    "\n",
    "# 2\n",
    "def zero_ls(circle, ls):\n",
    "    t = ''\n",
    "    if len(ls) == 1:\n",
    "        t = [i for i in range(ls[0],len(circle)+1)]\n",
    "    elif len(ls) > 1:\n",
    "        t = []\n",
    "        for l in ls:\n",
    "            ck = circle[l]\n",
    "            zero_plus(circle, l, ck,t)\n",
    "            \n",
    "    else:\n",
    "        t = 'X' # 바꿀 정보 없음\n",
    "    return t\n",
    "\n",
    "# 3\n",
    "def zero_change(high, dep, study, t): #\n",
    "    if t == 'X':\n",
    "        pass\n",
    "    elif len(t)>1:\n",
    "        for ti in t:\n",
    "            high[ti] = ''\n",
    "            dep[ti] = ''\n",
    "            study[ti] = 'N'\n",
    "\n",
    "# 4\n",
    "def zero_plus(circle, l, ck, t):   ## zero_ls의 후속함수\n",
    "    for i, v in enumerate(circle):\n",
    "        if i >= l and v == ck:\n",
    "            t.append(i)\n",
    "        else:\n",
    "            pass \n",
    "\n",
    "# 5\n",
    "def check_study(study, dep, etc_l):\n",
    "    for i in len(study):\n",
    "        if i != 0 and i != len(study):\n",
    "            if set(study[i-1:i+2]) == {'N'} and len(set(dep[i-1:i+2])) == 2:\n",
    "                for j in range(i-1, i+2):\n",
    "                    etc_l[j].append('std_lnk')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dad36ca",
   "metadata": {},
   "source": [
    "# action -  단권 자동화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43c1f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변수 설정\n",
    "isbn, tit, text = onePart['txtb_id'], onePart['set_isbn'], onePart['index']\n",
    "# 저장될 리스트\n",
    "bookID, mokchaID, high_mokchaID, contents, learning, depth,etc= [],[],[],[],[],[],[]\n",
    "start_pn, end_pn = [],[]\n",
    "noList = []\n",
    "\n",
    "# 목차 구분자\n",
    "ex = re.compile(\"제절|제편|제강|제항|제장|제회|제부|제과|제관|강|목|장|항|회|부|사례|총론|각론|부록|키워드|최근|실전|모의|문제|정답|해설|차례|전범위|참고|판례|핵심|시행|약점|연습|기출|t|book|part|chapter|day|section|theme|case|keyword|point|q|question|contents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bd497f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실행\n",
    "for i in range(len(text)):\n",
    "    try:\n",
    "        tet = make_ls(text, i)\n",
    "        index_classification(isbn, tit, tet, i, ex)\n",
    "    except:\n",
    "#         print('i')\n",
    "        noList.append(isbn[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1428716",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'txtb_id':bookID,'tcntn_id':mokchaID, 'uppr_tcntn_id':high_mokchaID,'tcntn_trn':etc,\\\n",
    "                   'tcntn_nm':contents, 'std_lnk_yn':learning, 'depth':depth,'str_page':start_pn})\n",
    "# end_page 열 만드는 작업\n",
    "end = start_pn[1:]\n",
    "end.append(np.NaN)\n",
    "data['end_page'] = end # 해당컬럼 추가\n",
    "data.loc[data['str_page'].isna(),'end_page'] = np.NaN # 데이터 정제\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69eb0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 정제 데이터 저장 \n",
    "# data.to_excel(\"C:/Users/sub computer/Desktop/추가_단권_목차.xlsx\",encoding = 'utf-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dded362d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 자동화되지 않은 데이터 구분\n",
    "noOne = onePart.loc[onePart['txtb_id'].isin(noList),:]\n",
    "noOne.index = range(len(noOne))\n",
    "noOne.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757e701c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 자동화 분류 개수\n",
    "len(onePart) - len(noOne) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58bb153",
   "metadata": {},
   "source": [
    "# action - 단권 수작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631409ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "noOne # 타깃 대상"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82815c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 목차 분류 구분자\n",
    "tex = re.compile(\"in|book|찾|주제|제절|제편|제강|제항|제장|제회|제부|제과|제관|강|목|장|항|회|부|사례|총론|각론|부록|키워드|최근|실전|모의|문제|정답|해설|차례|전범위|참고|판례|핵심|시행|약점|연습|기출|t|book|part|chapter|day|section|theme|case|keyword|point|q|question|contents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bf6183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 초기화\n",
    "isbn, tit, text = noOne['isbn'], noOne['set_isbn'], noOne['index']\n",
    "\n",
    "bookID, mokchaID, high_mokchaID, contents, learning, depth,etc= [],[],[],[],[],[],[]\n",
    "start_pn, end_pn = [],[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847af842",
   "metadata": {},
   "outputs": [],
   "source": [
    "num =  # 대상 인덱스\n",
    "code = isbn[num]\n",
    "text = make_ls(text, num)\n",
    "print(code)\n",
    "text\n",
    "# 해당 데이터 형태를 확인하여 반자동화(1) 또는 올수작업(2)을 선택하여 작업"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123194ba",
   "metadata": {},
   "source": [
    "### 반자동화\n",
    "- 작업을 위한 구분자 추가\n",
    "- 분류되지 않아도 무방한 대상이 존재시 체크 부분을 통해 제어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71643c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if '목차 더보기' in text: # 잘못 들어간 단어 삭제(틀 전체로 접근하다 보니 같이 달려옴)\n",
    "    text.remove('목차 더보기')\n",
    "    print(0)\n",
    "text = [clear_text(r) for r in text] # 이상한 문자 제거\n",
    "text = [delete_text(r) for r in text]\n",
    "print(1)\n",
    "splitKwd,index_ls, splitKwd_ls, page_ls,etc_ls = classification_contents(text,tex) # 구분자 체크\n",
    "print(2,splitKwd)\n",
    "if '총론' in splitKwd and '각론' in splitKwd:\n",
    "    splitKwd.remove('각론')\n",
    "    splitKwd_ls = ['총론' if c == '각론' else c for c in splitKwd_ls]\n",
    "# 체크    \n",
    "if 'check' not in splitKwd: # if 'check' in pandan:\n",
    "    tcntnID = [f'n{f\"{i}\".zfill(4)}' for i in range(len(splitKwd_ls))] \n",
    "    dep = assign_depth(splitKwd_ls)\n",
    "    print(3)\n",
    "    bin_ls = circle(splitKwd_ls,splitKwd)\n",
    "    high = assign_highID(tcntnID, dep)\n",
    "    study = assign_study(dep) \n",
    "    print(4)\n",
    "    no_ls = notStudy_change(index_ls)\n",
    "    no_lss = zero_ls(bin_ls, no_ls)\n",
    "    print(no_lss)\n",
    "    try:\n",
    "        zero_change(high, dep, study, no_lss)\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    for ti in tcntnID:\n",
    "        mokchaID.append(ti)\n",
    "    for ii in index_ls:\n",
    "        contents.append(ii)\n",
    "    for pi in page_ls:\n",
    "        start_pn.append(pi)\n",
    "    for di in dep:\n",
    "        depth.append(di)\n",
    "    for hi in high:\n",
    "        high_mokchaID.append(hi)\n",
    "    for si in study:\n",
    "        learning.append(si)   \n",
    "    for ei in etc_ls:\n",
    "        etc.append(ei)\n",
    "    for j in range(len(index_ls)):\n",
    "        bookID.append(f'm{code}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0a562b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame({'txtb_id':bookID,'tcntn_id':mokchaID, 'uppr_tcntn_id':high_mokchaID,'tcntn_trn':etc, \\\n",
    "                   'tcntn_nm':contents,'std_ln_yn':learning,'depth':depth, 'str_page':start_pn})\n",
    "end = start_pn[1:]\n",
    "end.append(np.NaN)\n",
    "test # 결과 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9eaa4f",
   "metadata": {},
   "source": [
    "### 올수작업\n",
    "- 텍스트와 페이지 넘버 분리만 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee6f651",
   "metadata": {},
   "outputs": [],
   "source": [
    "line, page = [],[]\n",
    "if '목차 더보기' in text: # 잘못 들어간 단어 삭제(틀 전체로 접근하다 보니 같이 달려옴)\n",
    "    text.remove('목차 더보기')\n",
    "    print(0)\n",
    "text = [clear_text(r) for r in text] # 이상한 문자 제거\n",
    "text = [delete_text(r) for r in text]\n",
    "for t in text:\n",
    "    l, pn, k= split_pn2(t)\n",
    "    line.append(l)\n",
    "    page.append(pn)\n",
    "    \n",
    "test = pd.DataFrame({'line':line,'page':page})\n",
    "test['code'] = f'm{code}'\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7634f4b8",
   "metadata": {},
   "source": [
    "### 저장 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0b95ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test.to_excel(\"C:/Users/sub computer/Desktop/추가단권_수작업++.xlsx\",encoding = 'utf-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9566d3",
   "metadata": {},
   "source": [
    "# action - 세트 자동화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768d243e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 세트권 유니크값 리스트화\n",
    "setp = setPart['set_isbn'].unique().tolist()\n",
    "\n",
    "# 세트별 개별권 데이터 프레임 \n",
    "setp_ls = []\n",
    "for sp in setp:\n",
    "    x = setPart.loc[setPart['set_isbn'] == sp, 'isbn'].tolist()\n",
    "    setp_ls.append(x)\n",
    "    \n",
    "setp_df = pd.DataFrame({'set_isbn': setp, 'isbn_ls' : setp_ls})\n",
    "setp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241df146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 타깃 정리\n",
    "setp_df = pd.merge(setp_df, setPart[['isbn','txtb_nm','index']], left_on= 'set_isbn',\\\n",
    "                   right_on = 'isbn')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988600f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변수 설정\n",
    "isbn, text = setp_df['isbn'],  setp_df['index']\n",
    "# 저장될 리스트\n",
    "bookID, mokchaID, high_mokchaID, contents, learning, depth,etc= [],[],[],[],[],[],[]\n",
    "start_pn, end_pn = [],[]\n",
    "noList = []\n",
    "\n",
    "ex = re.compile(\"제절|제편|제강|제항|제장|제회|제부|제과|제관|강|목|장|항|회|부|사례|총론|각론|부록|키워드|최근|실전|모의|문제|정답|해설|차례|전범위|참고|판례|핵심|시행|약점|연습|기출|t|book|part|chapter|day|section|theme|case|keyword|point|q|question|contents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ad4169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실행\n",
    "for i in range(len(text)):\n",
    "    try:\n",
    "        tet = make_ls(text, i)\n",
    "        clear_idx(isbn, tit, tet, i, ex)\n",
    "    except:\n",
    "#         print('i')\n",
    "        noList.append(isbn[i])\n",
    "    \n",
    "data = pd.DataFrame({'txtb_id':bookID,'tcntn_id':mokchaID, 'uppr_tcntn_id':high_mokchaID,'tcntn_trn':etc,\\\n",
    "                   'tcntn_nm':contents, 'stdy_lnk_yn':learning, 'depth':depth,'str_page':start_pn})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c871e449",
   "metadata": {},
   "outputs": [],
   "source": [
    "noSet = setp_df.loc[setp_df['isbn'].isin(noList),:]\n",
    "noSet.index = range(len(noSet))\n",
    "noSet.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebef6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(setp_df) - len(noSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276ee21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 저장\n",
    "# data.to_excel(\"C:/Users/sub computer/Desktop/경찰나머지_세트_목차.xlsx\",encoding = 'utf-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b339004d",
   "metadata": {},
   "source": [
    "# action - 세트 수작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03e7537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 목차 분류 구분자\n",
    "tex = re.compile(\"in|book|찾|주제|제절|제편|제강|제항|제장|제회|제부|제과|제관|강|목|장|항|회|부|사례|총론|각론|부록|키워드|최근|실전|모의|문제|정답|해설|차례|전범위|참고|판례|핵심|시행|약점|연습|기출|t|book|part|chapter|day|section|theme|case|keyword|point|q|question|contents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427a14d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 초기화\n",
    "isbn, tit, text = noSet['isbn'], noSet['set_isbn'], noSet['index']\n",
    "\n",
    "bookID, mokchaID, high_mokchaID, contents, learning, depth,etc= [],[],[],[],[],[],[]\n",
    "start_pn, end_pn = [],[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2454643e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num =  # 대상 인덱스\n",
    "code = isbn[num]\n",
    "text = make_ls(text, num)\n",
    "print(code)\n",
    "text\n",
    "# 해당 데이터 형태를 확인하여 반자동화(1) 또는 올수작업(2)을 선택하여 작업"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c0b5cd",
   "metadata": {},
   "source": [
    "### 반자동화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd21f473",
   "metadata": {},
   "outputs": [],
   "source": [
    "if '목차 더보기' in text: # 잘못 들어간 단어 삭제(틀 전체로 접근하다 보니 같이 달려옴)\n",
    "    text.remove('목차 더보기')\n",
    "    print(0)\n",
    "text = [clear_text(r) for r in text] # 이상한 문자 제거\n",
    "text = [delete_text(r) for r in text]\n",
    "print(1)\n",
    "splitKwd,index_ls, splitKwd_ls, page_ls,etc_ls = classification_contents(text,tex) # 구분자 체크\n",
    "print(2,splitKwd)\n",
    "if '총론' in splitKwd and '각론' in splitKwd:\n",
    "    splitKwd.remove('각론')\n",
    "    splitKwd_ls = ['총론' if c == '각론' else c for c in splitKwd_ls]\n",
    "# 체크    \n",
    "if 'check' not in splitKwd: # if 'check' in pandan:\n",
    "    tcntnID = [f'n{f\"{i}\".zfill(3)}' for i in range(len(splitKwd_ls))] \n",
    "    dep = assign_depth(splitKwd_ls)\n",
    "    print(3)\n",
    "    bin_ls = circle(splitKwd_ls,splitKwd)\n",
    "    high = assign_highID(tcntnID, dep)\n",
    "    study = assign_study(dep) \n",
    "    print(4)\n",
    "    no_ls = notStudy_change(index_ls)\n",
    "    no_lss = zero_ls(bin_ls, no_ls)\n",
    "    print(no_lss)\n",
    "    try:\n",
    "        zero_change(high, dep, study, no_lss)\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    for ti in tcntnID:\n",
    "        mokchaID.append(ti)\n",
    "    for ii in index_ls:\n",
    "        contents.append(ii)\n",
    "    for pi in page_ls:\n",
    "        start_pn.append(pi)\n",
    "    for di in dep:\n",
    "        depth.append(di)\n",
    "    for hi in high:\n",
    "        high_mokchaID.append(hi)\n",
    "    for si in study:\n",
    "        learning.append(si)   \n",
    "    for ei in etc_ls:\n",
    "        etc.append(ei)\n",
    "    for j in range(len(index_ls)):\n",
    "        bookID.append(f'm{code}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb498c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame({'txtb_id':bookID,'tcntn_id':mokchaID, 'uppr_tcntn_id':high_mokchaID,'tcntn_trn':etc, \\\n",
    "                   'tcntn_nm':contents,'std_ln_yn':learning,'depth':depth, 'str_page':start_pn})\n",
    "end = start_pn[1:]\n",
    "end.append(np.NaN)\n",
    "test['end_page'] = end # 해당컬럼 추가\n",
    "test.loc[data['str_page'].isna(),'end_page'] = np.NaN # 데이터 정제\n",
    "\n",
    "test # 결과 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c2ed70",
   "metadata": {},
   "source": [
    "### 올수작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f32d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "line, page = [],[]\n",
    "if '목차 더보기' in text: # 잘못 들어간 단어 삭제(틀 전체로 접근하다 보니 같이 달려옴)\n",
    "    text.remove('목차 더보기')\n",
    "    print(0)\n",
    "text = [clear_text(r) for r in text] # 이상한 문자 제거\n",
    "text = [delete_text(r) for r in text]\n",
    "for t in text:\n",
    "    l, pn, k= split_page(t)\n",
    "    line.append(l)\n",
    "    page.append(pn)\n",
    "    \n",
    "test = pd.DataFrame({'line':line,'page':page})\n",
    "test['code'] = f'm{code}'\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a631cb3f",
   "metadata": {},
   "source": [
    "### 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "259c8e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test.to_excel(\"C:/Users/sub computer/Desktop/경찰나머지_세트_수작업+.xlsx\",encoding = 'utf-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bade7e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
